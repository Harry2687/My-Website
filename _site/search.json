[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harry Zhong",
    "section": "",
    "text": "About Me\n\nHello and welcome to my website! I’m Harry, an Actuary (AIAA) working as a Data Analyst.\nI made this website as a way to document various personal projects I’m working on and to showcase my achievements and plans for the future. This website is still a work in progress, but feel free to look around.\nIf you want to know more about me, feel free to contact me via email or connect with me on LinkedIn. Thanks for visiting!\n\n\n Experience\n\nEBM Insurance & Risk | Data Intelligence Analyst | Nov 2022 - Present\n\n\n Education\n\nActuaries Institute | Actuary Program | Jul 2023 - Oct 2023\nCurtin University | Bachelor of Science (Actuarial Science) (Honours) | Feb 2019 - Jun 2023"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Harry Zhong",
    "section": "",
    "text": "Hello and welcome to my website! I’m Harry, an Actuary (AIAA) working as a Data Analyst.\nI made this website as a way to document various personal projects I’m working on and to showcase my achievements and plans for the future. This website is still a work in progress, but feel free to look around.\nIf you want to know more about me, feel free to contact me via email or connect with me on LinkedIn. Thanks for visiting!"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Harry Zhong",
    "section": " Experience",
    "text": "Experience\nEBM Insurance & Risk | Data Intelligence Analyst | Nov 2022 - Present"
  },
  {
    "objectID": "goals/index.html",
    "href": "goals/index.html",
    "title": "My Timeline",
    "section": "",
    "text": "Future Goals\n\n\n Past Achievements\n\n2023\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of My Spotify Data\n\n\n\nK-means\n\n\nR\n\n\n\nCategorisation of my Spotify listening history using k-means clustering.\n\n\n\nHarry Zhong\n\n\nMar 17, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Harry Zhong",
    "section": " Education",
    "text": "Education\nActuaries Institute | Actuary Program | Jul 2023 - Oct 2023\nCurtin University | Bachelor of Science (Actuarial Science) (Honours) | Feb 2019 - Jun 2023"
  },
  {
    "objectID": "goals/index.html#bachelor-of-science-actuarial-science-with-distinction",
    "href": "goals/index.html#bachelor-of-science-actuarial-science-with-distinction",
    "title": "My Timeline",
    "section": "##### Bachelor of Science (Actuarial Science) with Distinction",
    "text": "##### Bachelor of Science (Actuarial Science) with Distinction\n\nRecipient of the Curtin Excellence Scholarship.\n\n\n2023\n\n\n Future Goals"
  },
  {
    "objectID": "goals/index.html#past-achievements",
    "href": "goals/index.html#past-achievements",
    "title": "My Timeline",
    "section": " Past Achievements",
    "text": "Past Achievements\n\n2023\n\n\nQualified as an Associate Actuary (AIAA).\n\nStudied and passed Asset Liability Management and Communication, Modelling and Professionalism, thus completing the Actuary Program while working full time.\n\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) (Honours).\n\n78% Course weighted average.\nCompleted Data Analytics Principles and Actuarial Control Cycle subjects as part of the Actuaries Institute Actuary Program.\nCompleted my honours dissertation (graded 82%): Comparing Stochastic and Constant Volatility Returns Distributions using the Heston Model.\n\n\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk.\n\n\n\n2021\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction.\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "timeline/index.html#past-achievements",
    "href": "timeline/index.html#past-achievements",
    "title": "My Timeline",
    "section": " Past Achievements",
    "text": "Past Achievements\n\n2023\n\n\nQualified as an Associate Actuary (AIAA).\n\nStudied and passed Asset Liability Management and Communication, Modelling and Professionalism, thus completing the Actuary Program while working full time.\n\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) (Honours).\n\n78% Course weighted average.\nCompleted Data Analytics Principles and Actuarial Control Cycle subjects as part of the Actuaries Institute Actuary Program.\nCompleted my honours dissertation (graded 82%): Comparing Stochastic and Constant Volatility Returns Distributions using the Heston Model.\n\n\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk.\n\n\n\n2021\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction.\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "projects/spotify-analysis/index.html",
    "href": "projects/spotify-analysis/index.html",
    "title": "Analysis of My Spotify Data",
    "section": "",
    "text": "The motivation for this project was:\n\nI like music.\nI wanted to learn about clustering.\n\nSo, let’s get into how we can use R and Spotify’s Web API to categorise songs that we have listened to."
  },
  {
    "objectID": "projects/spotify-analysis/index.html#spotify-history-data",
    "href": "projects/spotify-analysis/index.html#spotify-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Spotify History Data",
    "text": "Spotify History Data\n\n\nShow code\nfiles &lt;- list.files(\"data/full_history_data\", \n                    pattern = \"*.json\", \n                    full.names = TRUE)\n\nfull_streaming_history &lt;- foreach(file = files, \n                                  .packages = c(\"jsonlite\"),\n                                  .combine = rbind) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(track_name = \"master_metadata_track_name\",\n         artist_name = \"master_metadata_album_artist_name\") %&gt;%\n  mutate(track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n         month = ts %&gt;%\n           substring(1, 7) %&gt;%\n           paste0(\"-01\") %&gt;%\n           ymd()) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#track-feature-data",
    "href": "projects/spotify-analysis/index.html#track-feature-data",
    "title": "Analysis of My Spotify Data",
    "section": "Track Feature Data",
    "text": "Track Feature Data\nNext, we’ll need to use Spotify’s Web API to obtain track features, which requires the track ID of each track we’re interested in. Fortunately, since we requested our full activity history, this data is included as a column.\nWe can use the httr and jsonlite packages to create a function that takes a Spotify track ID and returns its track features.\n\nget_audio_features &lt;- function(track_id) {\n  url = paste0(\"https://api.spotify.com/v1/audio-features/\", track_id)\n  response &lt;- GET(\n    url,\n    add_headers(Authorization = paste(\"Bearer\", spotify_token))\n  )\n  data &lt;- fromJSON(\n    content(\n      response, \n      \"text\", \n      encoding = \"UTF-8\"\n    )\n  )\n  return(data)\n}\n\nGiven the large number of track IDs, using this function on all tracks in our dataset is a long and painful process, where we will get rate limited many times by Spotify. Conveniently, I have a local file containing all of our tracks and their associated track features, which I will load in.\nThe description for each feature can be found in Spotify’s documentation.\n\nfull_track_features &lt;- read_csv(\"data/feature_data/full_track_features.csv\")\n\n\nhead(full_track_features)\n\n# A tibble: 6 × 16\n  track_name      artist_name track_uri danceability energy   key loudness  mode\n  &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Another Love -… Tom Odell   5snyhxAh…        0.87   0.554     4    -5.83     0\n2 Fire (feat. Pi… Jason Deru… 4tKDNJH4…        0.703  0.888    11    -4.72     0\n3 In Bloom - Nev… Nirvana     07bEZWP1…        0.438  0.851    10    -5.80     0\n4 Female Robbery  The Neighb… 7e8bQb1c…        0.403  0.888     7    -3.38     0\n5 The Monster     Eminem      5U8hKxSa…        0.784  0.85      9    -3.68     1\n6 Parking Lot (s… Eminem      5x3lJLcn…        0.43   0.771     7    -9.74     0\n# ℹ 8 more variables: speechiness &lt;dbl&gt;, acousticness &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, valence &lt;dbl&gt;, tempo &lt;dbl&gt;,\n#   duration_ms &lt;dbl&gt;, time_signature &lt;dbl&gt;\n\n\n\nfeature_matrix &lt;- full_track_features %&gt;%\n  mutate(track_artist = paste(track_name, artist_name, sep = \" - \")) %&gt;%\n  select(-track_name, -artist_name) %&gt;%\n  column_to_rownames(var = \"track_artist\") %&gt;%\n  select(-track_uri,\n         -key,\n         -mode,\n         -time_signature) %&gt;%\n  scale()"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#what-is-k-means",
    "href": "projects/spotify-analysis/index.html#what-is-k-means",
    "title": "Analysis of My Spotify Data",
    "section": "What is K-means?",
    "text": "What is K-means?"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#feature-selection",
    "href": "projects/spotify-analysis/index.html#feature-selection",
    "title": "Analysis of My Spotify Data",
    "section": "Feature selection",
    "text": "Feature selection\n\n\nShow code\nkmeans_select_features &lt;- function(n, data, nstart, itermax) {\n  n_factors &lt;- n\n  \n  comb_n &lt;- data %&gt;%\n    colnames() %&gt;%\n    combn(n_factors, simplify = FALSE)\n  \n  old_cols &lt;- seq(1, n_factors)\n  new_cols &lt;- paste0(\"factor_\", seq(1, n_factors))\n  \n  new_cols_sym &lt;- syms(new_cols)\n  \n  factor_combinations_n &lt;- do.call(rbind.data.frame, comb_n) %&gt;%\n    rename_with(~new_cols, all_of(old_cols)) %&gt;%\n    mutate(factors = pmap(list(!!!new_cols_sym), c)) %&gt;%\n    select(-(!!new_cols)) %&gt;%\n    mutate(data = map(factors,\n                      ~data %&gt;%\n                        as.data.frame() %&gt;%\n                        select(all_of(.x)))) %&gt;%\n    mutate(n_clusters = map(data,\n                            ~fviz_nbclust(.x, \n                                          kmeans, \n                                          nstart = nstart, \n                                          iter.max = itermax)[[\"data\"]] %&gt;%\n                              slice(which.max(y)) %&gt;%\n                              select(clusters) %&gt;%\n                              as.numeric(),\n                            .progress = paste(\"Finding optimal n_clusters:\", \n                                              n_factors, \n                                              \"factors\")) %&gt;%\n             as.numeric()) %&gt;% \n    mutate(km = map2(data,\n                     n_clusters,\n                     ~kmeans(.x, \n                             .y, \n                             nstart = nstart, \n                             iter.max = itermax,\n                             algorithm = \"MacQueen\"),\n                     .progress = paste(\"Calculating kmeans:\", \n                                       n_factors, \n                                       \"factors\"))) %&gt;%\n    mutate(total_withinss = map(km,\n                                ~.x$tot.withinss) %&gt;%\n             as.numeric(),\n           bsstssRatio = map(km,\n                             ~.x$betweenss/.x$totss) %&gt;%\n             as.numeric()) %&gt;%\n    mutate(km_plot = map2(km,\n                          data,\n                          ~fviz_cluster(.x,\n                                        data = .y,\n                                        geom = \"point\",\n                                        ellipse.type = \"convex\",\n                                        ggtheme = theme_bw()))) %&gt;%\n    arrange(desc(bsstssRatio))  \n  \n  return(factor_combinations_n)\n}\n\n\n\nset.seed(2687)\n\ncl &lt;- makeCluster(detectCores())\nregisterDoParallel(cl)\n\nstart_time &lt;- Sys.time()\n\nkmeans_nfact &lt;- foreach(n = seq(2, ncol(feature_matrix)),\n                                 .packages = c(\"tidyverse\",\n                                               \"cluster\",\n                                               \"factoextra\",\n                                               \"rlang\"),\n                                 .combine = bind_rows) %dopar% {\n                                   kmeans_select_features(n, \n                                                          feature_matrix, \n                                                          25, \n                                                          1000)\n                                 } %&gt;% \n  arrange(desc(bsstssRatio))\n\nend_time &lt;- Sys.time()\ntime_taken &lt;- end_time - start_time\n\nstopCluster(cl)"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#spotify-activity-history-data",
    "href": "projects/spotify-analysis/index.html#spotify-activity-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Spotify Activity History Data",
    "text": "Spotify Activity History Data\n\n\nShow code\nfiles &lt;- list.files(\"data/full_history_data\", \n                    pattern = \"*.json\", \n                    full.names = TRUE)\n\nfull_streaming_history &lt;- foreach(file = files, \n                                  .packages = c(\"jsonlite\"),\n                                  .combine = rbind) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(track_name = \"master_metadata_track_name\",\n         artist_name = \"master_metadata_album_artist_name\") %&gt;%\n  mutate(track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n         month = ts %&gt;%\n           substring(1, 7) %&gt;%\n           paste0(\"-01\") %&gt;%\n           ymd()) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#activity-history-data",
    "href": "projects/spotify-analysis/index.html#activity-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Activity History Data",
    "text": "Activity History Data\nOur Spotify activity history data is given as a set of .json files. We can extract the data from all the .json files into a dataframe and perform some preliminary cleaning using the code below.\n\n\nShow code\nfiles &lt;- list.files(\n  \"data/full_history_data\", \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\n      \"spotify:track:\", \n      \"\", \n      spotify_track_uri\n    ),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\n\nFrom here, we can use the ggplot2 and shiny packages to visualise trends in my most listened to artists and tracks.\n\n\n\napp.R\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(foreach)\n\nfiles &lt;- list.files(\n  paste0(here(), \"/data/full_history_data\"), \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\nmin_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  min()\n\nmax_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  max()\n\nui &lt;- fluidPage(\n  titlePanel(\"Spotify Streaming History\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\n        \"top_n_artists\",\n        \"Top n Artists\",\n        min = 1,\n        max = 20,\n        value = 10\n      ),\n      sliderInput(\n        \"top_n_tracks\",\n        \"Top n Tracks\",\n        min = 1,\n        max = 20,\n        value = 10\n      ),\n      sliderInput(\n        \"dates\",\n        \"Streaming History Date Range\",\n        min = min_date,\n        max = max_date,\n        value = c(max_date %m-% months(6), max_date)\n      )\n    ),\n    mainPanel(\n      tabsetPanel(\n        type = \"tabs\",\n        tabPanel(\n          \"Artist History Plot\", \n          h2(textOutput(\"artist_history_title\")),\n          plotOutput(\"artist_history_plot\")\n        ),\n        tabPanel(\n          \"Track History Plot\",\n          h2(textOutput(\"track_history_title\")),\n          plotOutput(\"track_history_plot\")\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  output$artist_history_title &lt;- renderText({\n    top_n_artists &lt;- input$top_n_artists\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n_artists,\n      \" Artists\"\n    )\n  })\n  \n  output$artist_history_plot &lt;- renderPlot({\n    top_artists &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_artists = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            group_by(artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n_artists)) %&gt;%\n            pull(artist_name)\n        )\n      )\n    \n    artist_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      left_join(\n        top_artists,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(artist_name %in% top_artists) %&gt;%\n      group_by(\n        artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(artist_summary, aes(x = month, y = hours_listened, fill = artist_name, label = artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n  \n  output$track_history_title &lt;- renderText({\n    top_n_tracks &lt;- input$top_n_tracks\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n_tracks,\n      \" Tracks\"\n    )\n  })\n  \n  output$track_history_plot &lt;- renderPlot({\n    top_tracks &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_tracks = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n            group_by(track_artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n_tracks)) %&gt;%\n            pull(track_artist_name)\n        )\n      )\n    \n    track_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n      left_join(\n        top_tracks,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(track_artist_name %in% top_tracks) %&gt;%\n      group_by(\n        track_artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(track_summary, aes(x = month, y = hours_listened, fill = track_artist_name, label = track_artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  }
]