[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harry Zhong",
    "section": "",
    "text": "About Me\n\nHello and welcome to my website! I’m Harry, an Actuary (AIAA) working as a Data Analyst.\nI made this website as a way to document various personal projects I’m working on and to showcase my achievements and plans for the future. This website is still a work in progress, but feel free to look around.\nIf you want to know more about me, feel free to contact me via email or connect with me on LinkedIn. Thanks for visiting!\n\n\n Experience\n\nEBM Insurance & Risk | Data Intelligence Analyst | Nov 2022 - Present\n\n\n Education\n\nActuaries Institute | Actuary Program | Jul 2023 - Oct 2023\nCurtin University | Bachelor of Science (Actuarial Science) (Honours) | Feb 2019 - Jun 2023"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Harry Zhong",
    "section": "",
    "text": "Hello and welcome to my website! I’m Harry, an Actuary (AIAA) working as a Data Analyst.\nI made this website as a way to document various personal projects I’m working on and to showcase my achievements and plans for the future. This website is still a work in progress, but feel free to look around.\nIf you want to know more about me, feel free to contact me via email or connect with me on LinkedIn. Thanks for visiting!"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Harry Zhong",
    "section": " Experience",
    "text": "Experience\nEBM Insurance & Risk | Data Intelligence Analyst | Nov 2022 - Present"
  },
  {
    "objectID": "goals/index.html",
    "href": "goals/index.html",
    "title": "My Timeline",
    "section": "",
    "text": "Future Goals\n\n\n Past Achievements\n\n2023\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of My Spotify Data\n\n\n\nK-means\n\n\nR\n\n\n\nCategorisation of my Spotify listening history using k-means clustering.\n\n\n\nHarry Zhong\n\n\nMar 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Harry Zhong",
    "section": " Education",
    "text": "Education\nActuaries Institute | Actuary Program | Jul 2023 - Oct 2023\nCurtin University | Bachelor of Science (Actuarial Science) (Honours) | Feb 2019 - Jun 2023"
  },
  {
    "objectID": "goals/index.html#bachelor-of-science-actuarial-science-with-distinction",
    "href": "goals/index.html#bachelor-of-science-actuarial-science-with-distinction",
    "title": "My Timeline",
    "section": "##### Bachelor of Science (Actuarial Science) with Distinction",
    "text": "##### Bachelor of Science (Actuarial Science) with Distinction\n\nRecipient of the Curtin Excellence Scholarship.\n\n\n2023\n\n\n Future Goals"
  },
  {
    "objectID": "goals/index.html#past-achievements",
    "href": "goals/index.html#past-achievements",
    "title": "My Timeline",
    "section": " Past Achievements",
    "text": "Past Achievements\n\n2023\n\n\nQualified as an Associate Actuary (AIAA).\n\nStudied and passed Asset Liability Management and Communication, Modelling and Professionalism, thus completing the Actuary Program while working full time.\n\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) (Honours).\n\n78% Course weighted average.\nCompleted Data Analytics Principles and Actuarial Control Cycle subjects as part of the Actuaries Institute Actuary Program.\nCompleted my honours dissertation (graded 82%): Comparing Stochastic and Constant Volatility Returns Distributions using the Heston Model.\n\n\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk.\n\n\n\n2021\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction.\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "timeline/index.html#past-achievements",
    "href": "timeline/index.html#past-achievements",
    "title": "My Timeline",
    "section": " Past Achievements",
    "text": "Past Achievements\n\n2023\n\n\nQualified as an Associate Actuary (AIAA).\n\nStudied and passed Asset Liability Management and Communication, Modelling and Professionalism, thus completing the Actuary Program while working full time.\n\n\n\n\nGraduated with Bachelor of Science (Actuarial Science) (Honours).\n\n78% Course weighted average.\nCompleted Data Analytics Principles and Actuarial Control Cycle subjects as part of the Actuaries Institute Actuary Program.\nCompleted my honours dissertation (graded 82%): Comparing Stochastic and Constant Volatility Returns Distributions using the Heston Model.\n\n\n\n\n2022\n\n\nStarted my first graduate job at EBM Insurance & Risk.\n\n\n\n2021\n\n\nGraduated with Bachelor of Science (Actuarial Science) with Distinction.\n\n85% Course weighted average.\nObtained all Actuaries Institute Foundation Program exemptions.\nRecipient of the Curtin Excellence Scholarship."
  },
  {
    "objectID": "projects/spotify-analysis/index.html",
    "href": "projects/spotify-analysis/index.html",
    "title": "Analysis of My Spotify Data",
    "section": "",
    "text": "The motivation for this project was:\n\nI like music.\nI wanted to learn about clustering.\n\nSo, let’s get into how we can use R and Spotify’s Web API to categorise songs that we have listened to."
  },
  {
    "objectID": "projects/spotify-analysis/index.html#spotify-history-data",
    "href": "projects/spotify-analysis/index.html#spotify-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Spotify History Data",
    "text": "Spotify History Data\n\n\nShow code\nfiles &lt;- list.files(\"data/full_history_data\", \n                    pattern = \"*.json\", \n                    full.names = TRUE)\n\nfull_streaming_history &lt;- foreach(file = files, \n                                  .packages = c(\"jsonlite\"),\n                                  .combine = rbind) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(track_name = \"master_metadata_track_name\",\n         artist_name = \"master_metadata_album_artist_name\") %&gt;%\n  mutate(track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n         month = ts %&gt;%\n           substring(1, 7) %&gt;%\n           paste0(\"-01\") %&gt;%\n           ymd()) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#track-feature-data",
    "href": "projects/spotify-analysis/index.html#track-feature-data",
    "title": "Analysis of My Spotify Data",
    "section": "Track Feature Data",
    "text": "Track Feature Data\nNext, we’ll need to use Spotify’s Web API to obtain track features, which requires the track ID of each track we’re interested in. Fortunately, since we requested our full activity history, this data is included as a column.\nWe can use the httr and jsonlite packages to create a function that takes a Spotify track ID and returns its track features.\n\nget_audio_features &lt;- function(track_id) {\n  url = paste0(\"https://api.spotify.com/v1/audio-features/\", track_id)\n  response &lt;- GET(\n    url,\n    add_headers(Authorization = paste(\"Bearer\", spotify_token))\n  )\n  data &lt;- fromJSON(\n    content(\n      response, \n      \"text\", \n      encoding = \"UTF-8\"\n    )\n  )\n  return(data)\n}\n\nGiven the large number of track IDs, using this function on all tracks in our dataset is a long and painful process, where we will get rate limited many times by Spotify. Conveniently, I have a local file containing all of our tracks and their associated track features, which I will load in.\nThe description for each feature can be found in Spotify’s documentation.\n\nfull_track_features &lt;- read_csv(\"data/feature_data/full_track_features.csv\")\n\n\nfull_track_features %&gt;%\n  head() %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrack_name\nartist_name\ntrack_uri\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nduration_ms\ntime_signature\n\n\n\n\nAnother Love - Zwette Edit\nTom Odell\n5snyhxAh55A2wlNRH7VVZJ\n0.870\n0.554\n4\n-5.828\n0\n0.0635\n8.02e-02\n7.39e-02\n0.1150\n0.4620\n123.998\n394573\n4\n\n\nFire (feat. Pitbull)\nJason Derulo\n4tKDNJH4ylLAxfwYqqUM1d\n0.703\n0.888\n11\n-4.724\n0\n0.0558\n1.06e-02\n2.80e-06\n0.1920\n0.7660\n128.047\n216133\n4\n\n\nIn Bloom - Nevermind Version\nNirvana\n07bEZWP1PqS5jCR0iiz1zt\n0.438\n0.851\n10\n-5.802\n0\n0.0505\n2.67e-05\n1.36e-04\n0.3010\n0.5920\n157.088\n253440\n4\n\n\nFemale Robbery\nThe Neighbourhood\n7e8bQb1csn5WvpOc4b5PJg\n0.403\n0.888\n7\n-3.382\n0\n0.0413\n5.60e-02\n1.61e-03\n0.0682\n0.3910\n176.483\n206813\n4\n\n\nThe Monster\nEminem\n5U8hKxSaDXB8cVeLFQjvwx\n0.784\n0.850\n9\n-3.679\n1\n0.0691\n4.92e-02\n0.00e+00\n0.1120\n0.5670\n110.004\n250189\n4\n\n\nParking Lot (skit)\nEminem\n5x3lJLcnH0naed3iWCmMiJ\n0.430\n0.771\n7\n-9.737\n0\n0.3380\n5.81e-01\n2.11e-01\n0.6930\n0.0927\n139.723\n55338\n4\n\n\n\n\n\nWe can then remove discrete track features and scale the remaining features so that the clusters are not affected by the difference in magnitude of different features.\n\nfeature_matrix &lt;- full_track_features %&gt;%\n  mutate(track_artist = paste(track_name, artist_name, sep = \" - \")) %&gt;%\n  select(\n    -track_name, \n    -artist_name\n  ) %&gt;%\n  column_to_rownames(var = \"track_artist\") %&gt;%\n  select(\n    -track_uri,\n    -key,\n    -mode,\n    -time_signature\n  ) %&gt;%\n  scale()\n\n\nfeature_matrix %&gt;%\n  head() %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndanceability\nenergy\nloudness\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nduration_ms\n\n\n\n\nAnother Love - Zwette Edit - Tom Odell\n1.7588032\n0.1631977\n0.6119183\n-0.1269820\n-1.0701754\n-0.1063739\n-0.4436225\n0.0878843\n0.2056935\n3.5338647\n\n\nFire (feat. Pitbull) - Jason Derulo\n0.6496091\n1.7291426\n0.8609006\n-0.2291247\n-1.2860575\n-0.3915547\n0.1662336\n1.4018309\n0.3412460\n0.3478386\n\n\nIn Bloom - Nevermind Version - Nirvana\n-1.1104893\n1.5556696\n0.6177820\n-0.2994308\n-1.3188533\n-0.3910409\n1.0295364\n0.6497693\n1.3134816\n1.0139509\n\n\nFemale Robbery - The Neighbourhood\n-1.3429551\n1.7291426\n1.1635585\n-0.4214714\n-1.1452379\n-0.3853525\n-0.8142883\n-0.2189914\n1.9627881\n0.1814311\n\n\nThe Monster - Eminem\n1.1876015\n1.5509812\n1.0965769\n-0.0526964\n-1.1663298\n-0.3915657\n-0.4673831\n0.5417145\n-0.2627981\n0.9559047\n\n\nParking Lot (skit) - Eminem\n-1.1636243\n1.1805930\n-0.2696688\n3.5143395\n0.4831829\n0.4227166\n4.1342585\n-1.5083016\n0.7321356\n-2.5231380"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#what-is-k-means",
    "href": "projects/spotify-analysis/index.html#what-is-k-means",
    "title": "Analysis of My Spotify Data",
    "section": "What is K-means?",
    "text": "What is K-means?"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#feature-selection",
    "href": "projects/spotify-analysis/index.html#feature-selection",
    "title": "Analysis of My Spotify Data",
    "section": "Feature selection",
    "text": "Feature selection\n\n\nShow code\nkmeans_select_features &lt;- function(n, data, nstart, itermax) {\n  comb_n &lt;- data %&gt;%\n    colnames() %&gt;%\n    combn(n, simplify = FALSE)\n  \n  old_cols &lt;- seq(1, n)\n  new_cols &lt;- paste0(\"factor_\", seq(1, n))\n  \n  new_cols_sym &lt;- syms(new_cols)\n  \n  factor_combinations_n &lt;- do.call(rbind.data.frame, comb_n) %&gt;%\n    rename_with(~new_cols, all_of(old_cols)) %&gt;%\n    mutate(factors = pmap(list(!!!new_cols_sym), c)) %&gt;%\n    mutate(n_factors = n) %&gt;%\n    select(-(!!new_cols)) %&gt;%\n    mutate(data = map(factors,\n                      ~data %&gt;%\n                        as.data.frame() %&gt;%\n                        select(all_of(.x)))) %&gt;%\n    mutate(n_clusters = map(data,\n                            ~fviz_nbclust(.x, \n                                          kmeans, \n                                          nstart = nstart, \n                                          iter.max = itermax)[[\"data\"]] %&gt;%\n                              slice(which.max(y)) %&gt;%\n                              select(clusters) %&gt;%\n                              as.numeric(),\n                            .progress = paste(\"Finding optimal n_clusters:\", \n                                              n, \n                                              \"factors\")) %&gt;%\n             as.numeric()) %&gt;% \n    mutate(km = map2(data,\n                     n_clusters,\n                     ~kmeans(.x, \n                             .y, \n                             nstart = nstart, \n                             iter.max = itermax,\n                             algorithm = \"MacQueen\"),\n                     .progress = paste(\"Calculating kmeans:\", \n                                       n, \n                                       \"factors\"))) %&gt;%\n    mutate(total_withinss = map(km,\n                                ~.x$tot.withinss) %&gt;%\n             as.numeric(),\n           bsstssRatio = map(km,\n                             ~.x$betweenss/.x$totss) %&gt;%\n             as.numeric()) %&gt;%\n    mutate(km_plot = map2(km,\n                          data,\n                          ~fviz_cluster(.x,\n                                        data = .y,\n                                        geom = \"point\",\n                                        ellipse.type = \"convex\"))) %&gt;%\n    arrange(desc(bsstssRatio))  \n  \n  return(factor_combinations_n)\n}\n\n\n\nset.seed(2687)\n\ncl &lt;- makeCluster(detectCores())\nregisterDoParallel(cl)\n\nkmeans_nfact &lt;- foreach(n = seq(2, ncol(feature_matrix)),\n                        .packages = c(\n                          \"tidyverse\",\n                          \"cluster\",\n                          \"factoextra\",\n                          \"rlang\"\n                        ),\n                        .combine = bind_rows) %dopar% {\n                          kmeans_select_features(n, feature_matrix, 25, 1000)\n                        } %&gt;% \n  arrange(desc(bsstssRatio))\n\nstopCluster(cl)\n\n\nload(\"data/R_data/kmeans_nfact.RData\")"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#spotify-activity-history-data",
    "href": "projects/spotify-analysis/index.html#spotify-activity-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Spotify Activity History Data",
    "text": "Spotify Activity History Data\n\n\nShow code\nfiles &lt;- list.files(\"data/full_history_data\", \n                    pattern = \"*.json\", \n                    full.names = TRUE)\n\nfull_streaming_history &lt;- foreach(file = files, \n                                  .packages = c(\"jsonlite\"),\n                                  .combine = rbind) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(track_name = \"master_metadata_track_name\",\n         artist_name = \"master_metadata_album_artist_name\") %&gt;%\n  mutate(track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n         month = ts %&gt;%\n           substring(1, 7) %&gt;%\n           paste0(\"-01\") %&gt;%\n           ymd()) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))"
  },
  {
    "objectID": "projects/spotify-analysis/index.html#activity-history-data",
    "href": "projects/spotify-analysis/index.html#activity-history-data",
    "title": "Analysis of My Spotify Data",
    "section": "Activity History Data",
    "text": "Activity History Data\nOur Spotify activity history data is given as a set of .json files. We can extract the data from all the .json files into a dataframe and perform some preliminary cleaning using the code below.\n\n\nShow code\nfiles &lt;- list.files(\n  \"data/full_history_data\", \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\n      \"spotify:track:\", \n      \"\", \n      spotify_track_uri\n    ),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(\n    -spotify_track_uri,\n    -username,\n    -platform,\n    -ip_addr_decrypted\n  ) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\n\n\nfull_streaming_history %&gt;%\n  head() %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nts\nms_played\nconn_country\nuser_agent_decrypted\ntrack_name\nartist_name\nmaster_metadata_album_album_name\nepisode_name\nepisode_show_name\nspotify_episode_uri\nreason_start\nreason_end\nshuffle\nskipped\noffline\noffline_timestamp\nincognito_mode\ntrack_uri\nmonth\n\n\n\n\n2019-04-05T00:20:46Z\n16939\nAU\nunknown\nConclusion\nAGM\nConclusion\nNA\nNA\nNA\nclickrow\nfwdbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1e92VSkCg0HIFwyxnDCfje\n2019-04-01\n\n\n2019-04-05T00:20:47Z\n13\nAU\nunknown\nTénegro\nChill Children\n001\nNA\nNA\nNA\nfwdbtn\nbackbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1zchrk1boRCyXkUcJ22yQZ\n2019-04-01\n\n\n2019-04-05T00:22:50Z\n122133\nAU\nunknown\nConclusion\nAGM\nConclusion\nNA\nNA\nNA\nbackbtn\nfwdbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1e92VSkCg0HIFwyxnDCfje\n2019-04-01\n\n\n2019-04-05T00:22:51Z\n977\nAU\nunknown\nTénegro\nChill Children\n001\nNA\nNA\nNA\nfwdbtn\nbackbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1zchrk1boRCyXkUcJ22yQZ\n2019-04-01\n\n\n2019-04-05T00:22:52Z\n1094\nAU\nunknown\nConclusion\nAGM\nConclusion\nNA\nNA\nNA\nbackbtn\nfwdbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1e92VSkCg0HIFwyxnDCfje\n2019-04-01\n\n\n2019-04-05T00:22:53Z\n434\nAU\nunknown\nTénegro\nChill Children\n001\nNA\nNA\nNA\nfwdbtn\nfwdbtn\nFALSE\nNA\nFALSE\n1.554424e+12\nFALSE\n1zchrk1boRCyXkUcJ22yQZ\n2019-04-01\n\n\n\n\n\nFrom here, we can use the ggplot2 and shiny packages to visualise trends in my most listened to artists and tracks.\n\n\n\napp.R\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(foreach)\n\nfiles &lt;- list.files(\n  paste0(here(), \"/data/full_history_data\"), \n  pattern = \"*.json\", \n  full.names = TRUE\n)\n\nfull_streaming_history &lt;- foreach(\n  file = files, \n  .packages = c(\"jsonlite\"),\n  .combine = rbind\n) %do% {\n  fromJSON(file, flatten = TRUE)\n} %&gt;%\n  rename(\n    track_name = \"master_metadata_track_name\",\n    artist_name = \"master_metadata_album_artist_name\"\n  ) %&gt;%\n  mutate(\n    track_uri = gsub(\"spotify:track:\", \"\", spotify_track_uri),\n    month = ts %&gt;%\n      substring(1, 7) %&gt;%\n      paste0(\"-01\") %&gt;%\n      ymd()\n  ) %&gt;%\n  select(-spotify_track_uri) %&gt;%\n  filter(month &gt;= ymd(\"2019-04-01\"))\n\nmin_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  min()\n\nmax_date &lt;- full_streaming_history %&gt;%\n  pull(month) %&gt;%\n  max()\n\nui &lt;- fluidPage(\n  titlePanel(\"Spotify Streaming History\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\n        \"top_n_artists\",\n        \"Top n Artists\",\n        min = 1,\n        max = 20,\n        value = 10\n      ),\n      sliderInput(\n        \"top_n_tracks\",\n        \"Top n Tracks\",\n        min = 1,\n        max = 20,\n        value = 10\n      ),\n      sliderInput(\n        \"dates\",\n        \"Streaming History Date Range\",\n        min = min_date,\n        max = max_date,\n        value = c(max_date %m-% months(6), max_date)\n      )\n    ),\n    mainPanel(\n      tabsetPanel(\n        type = \"tabs\",\n        tabPanel(\n          \"Artist History Plot\", \n          h2(textOutput(\"artist_history_title\")),\n          plotOutput(\"artist_history_plot\")\n        ),\n        tabPanel(\n          \"Track History Plot\",\n          h2(textOutput(\"track_history_title\")),\n          plotOutput(\"track_history_plot\")\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  output$artist_history_title &lt;- renderText({\n    top_n_artists &lt;- input$top_n_artists\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n_artists,\n      \" Artists\"\n    )\n  })\n  \n  output$artist_history_plot &lt;- renderPlot({\n    top_artists &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_artists = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            group_by(artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n_artists)) %&gt;%\n            pull(artist_name)\n        )\n      )\n    \n    artist_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      left_join(\n        top_artists,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(artist_name %in% top_artists) %&gt;%\n      group_by(\n        artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(artist_summary, aes(x = month, y = hours_listened, fill = artist_name, label = artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n  \n  output$track_history_title &lt;- renderText({\n    top_n_tracks &lt;- input$top_n_tracks\n    \n    paste0(\n      \"Proportion of Hours Listened: Top \",\n      top_n_tracks,\n      \" Tracks\"\n    )\n  })\n  \n  output$track_history_plot &lt;- renderPlot({\n    top_tracks &lt;- data.frame(\n      month = full_streaming_history %&gt;%\n        select(month) %&gt;%\n        distinct()\n    ) %&gt;%\n      mutate(\n        top_tracks = map(\n          month,\n          ~full_streaming_history %&gt;%\n            filter(month == .x) %&gt;%\n            mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n            group_by(track_artist_name) %&gt;%\n            summarise(time = sum(ms_played)) %&gt;%\n            slice_max(time, n = as.numeric(input$top_n_tracks)) %&gt;%\n            pull(track_artist_name)\n        )\n      )\n    \n    track_summary &lt;- full_streaming_history %&gt;%\n      filter(\n        month %&gt;%\n          between(input$dates[1], input$dates[2])\n      ) %&gt;%\n      mutate(track_artist_name = paste(track_name, artist_name, sep = \"\\n\")) %&gt;%\n      left_join(\n        top_tracks,\n        by = \"month\"\n      ) %&gt;%\n      rowwise() %&gt;%\n      filter(track_artist_name %in% top_tracks) %&gt;%\n      group_by(\n        track_artist_name, \n        month\n      ) %&gt;%\n      summarise(hours_listened = sum(ms_played/(1000*60)))\n    \n    ggplot(track_summary, aes(x = month, y = hours_listened, fill = track_artist_name, label = track_artist_name)) +\n      xlab(\"Date\") +\n      ylab(\"Proportion\") +\n      geom_bar(position = \"fill\", stat = \"identity\") +\n      geom_text(size = 3, position = position_fill(vjust = 0.5)) +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui = ui, server = server)"
  }
]